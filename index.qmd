---
title: "Dynamic AI Occupational Exposure Index"
page-layout: full
repo-actions: false
format:
  html: 
    grid:
      body-width: 900px
      margin-width: 250px
reference-location: document
# citation-location: margin
bibliography: references.bib
---

## What it is? (in plain English)

DAIOE tracks how advances in artificial intelligence change the potential impact of AI on different occupations over time. Itâ€™s a panel index (2010â€“) that updates annually and distinguishes between nine major AI subdomains (e.g., language modeling, image generation, speech recognition). Think of it as a moving barometer of where AI capabilities could matter mostâ€”not as a forecast of job loss or gain. The net employment effect, e.g., depends on how organisations adopt and apply AI.

## Why itâ€™s useful?

Because DAIOE is dynamic and subdomain-specific, itâ€™s better aligned with real technical progress than static, one-shot measures. In essence, it "unpacks" AI--enabling analysis of how exposed occupations are to different types of AI. By combining DAIOE with other data that have occupation codes, such as industry-level data or linked employer-employee data, researchers and policymakers can trace exposure by occupation, sector, skill level, or country (e.g., Denmark, Portugal, Sweden in our firm-level applications), and test whether AI exposure is associated with up-skilling or reallocation inside firms and industries. In our firm-level evidence, total employment associations are small on average, but exposure is linked to a higher share of high-skilled white-collar work and a lower share of low-skill clerical roles. Meanwhile, results differ meaningfully across different types of AI, underlining the importance of "unpacking" exposure to AI.

## DAIOE-at-a-glance

-   **Coverage**: 2010â€“ (currently, 2023)

-   **AI subdomains**: 9, related to games, language, and images

-   **Occupations**: ISCO-08, SOC2010 and SSYK2012

-   **Granularity**: virtually all occupations; sub-indices by subdomain.

-   **Add-ons**: one overall and another generative AI version.

-   **Total number of indices**: 11 (1 overall; 1 genAI; 9 sub-indices)

-   **Meaning**: Exposure = potential applicability of AI capabilities to occupational content (not adoption or automation probability).

## Technical specification (short)

Construction (overview)

DAIOE combines

1.  AI capability progress by subdomain with

2.  Occupational work content.

First, we assemble yearly measures of AI performance across nine applications (e.g., language, vision, speech), drawing on standardised evaluation benchmarks and leaderboards. Second, we map those AI abilities to the skills and abilities that define each occupation. Finally, for each occupationâ€“year, we take a weighted aggregation (a â€œmatchâ€ between capability growth and occupational requirements) to form the exposure index and its nine sub-indices as well as two off-springs (the genAI- and non-genAI versions).

## Formal details

### Capturing AI capability progress

We track yearly progress in nine AI subdomainsâ€”games (abstract strategy, real-time), vision (recognition, comprehension, generation), language (reading comprehension, language modelling, translation), and speech recognitionâ€”using 140 benchmarks that have been used to test model performance in AI research (sources: EFF and Papers With Code). For each benchmark, we derive a frontier curve, indicating the state-of-the-art at a given time. Metrics are harmonised so changes are comparable, then summarised each year to capture shifts in the technical frontier.

### From capabilities to occupations

Subdomain progress is mapped to 52 O\*NET abilities via the [Felten et al. (2018)](https://www.aeaweb.org/articles?id=10.1257/pandp.20181021) 9Ã—52 matrix. Ability-level exposure is aggregated to occupations with O\*NET importanceÃ—level weights, yielding an annual exposure change and nine parallel sub-indices. To pay attention to interpersonal roles, we apply a calibrated social-skills discount and then cumulate the annual exposure changes from 2010â€“ to form the DAIOE panel.

### Interpretation

DAIOE measures the potential applicability of AI to occupational content, over timeâ€”not adoption or automation probabilities. Real-world effects, e.g., depend on the development and adoption of AI applications, complementary investments, organisational choices, and policy.

## AI sub-domains

::: {.callout-tip title="AI Subdomains" collapse="false" icon="false"}
1.  â™Ÿï¸ Abstract strategy games â€” tests long-horizon planning & search.

2.  ğŸ® Real-time video games â€” adaptive control under time pressure.

3.  ğŸ–¼ï¸ğŸ” Image recognition â€” identifying objects & patterns in images.

4.  ğŸ§©ğŸ–¼ï¸ Image comprehension â€” reasoning about what an image depicts.

5.  ğŸ–Œï¸ğŸ–¼ï¸ Image generation â€” creating or editing visual content.

6.  ğŸ“– Reading comprehension â€” extracting and using information from text.

7.  âœï¸ğŸ¤– Language modelling â€” generating and transforming text.

8.  ğŸŒğŸ”¤ Translation â€” converting meaning across languages.

9.  ğŸ—£ï¸ğŸ™ï¸ Speech recognition â€” turning audio into text reliably.
:::

## Links, downloads and "README"

The original paper The DAIOE is developed, explained, validated, and applied in the most current version of the paper by Engberg et al. (2025)[^1].

[^1]: [Engberg et al. (2025)](https://drive.google.com/file/d/1hHIGmXC8j0GDDkCJuZ76ub63Hq7CgRbS/view)

Suggested citation: @engberg2024

DAIOE data can be downloaded â¡ï¸ [Github](https://github.com/joseph-data/daioe_dataset) (2010 to latest available year) and can be cited as @nyajuoga.